{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Installations\n",
        "%%capture\n",
        "!pip install pandas numpy scikit-learn statsmodels networkx matplotlib seaborn torch numba\n"
      ],
      "metadata": {
        "id": "TyKLXLegbiUh"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**casual_rules.py**"
      ],
      "metadata": {
        "id": "4SiEDkwKbprh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile causal_rules.pyreason\n",
        "# Basic PyReason rules\n",
        "\n",
        "# Example Rule 1: If it rains, the ground is wet.\n",
        "@context(f'{t} and not {t-1}')\n",
        "@forall(a, b)\n",
        "def rule1(a: entity, b: entity):\n",
        "    if a in Rains and b in Ground:\n",
        "        return Wet(b)\n",
        "\n",
        "# Example Rule 2: If the ground is wet and the sun is shining, it might steam.\n",
        "@context(f'{t} and {t-1}')\n",
        "@forall(a)\n",
        "def rule2(a: entity):\n",
        "    if Wet(a) and SunShining():\n",
        "        return Steam(a) @ 0.7\n",
        "\n",
        "# Example Rule 3: If plants are not watered, they may wither.\n",
        "@context(f'{t}')\n",
        "@forall(p)\n",
        "def rule3(p: entity):\n",
        "    if p in Plants and NotWatered(p):\n",
        "        return Wither(p) @ 0.9\n",
        "\n",
        "# Example Rule 4: If homework is not done, there may be trouble.\n",
        "@context(f'{t}')\n",
        "@forall(s)\n",
        "def rule4(s: entity):\n",
        "    if s in Students and NotDone(Homework(s)):\n",
        "        return Trouble(s)\n",
        "\n",
        "# Example Rule 5: If you sleep late, you feel tired the next day.\n",
        "@context(f'{t} and {t+1}')\n",
        "@forall(p)\n",
        "def rule5(p: entity):\n",
        "    if p in Persons and SleepLate(p):\n",
        "        return Tired(p)\n",
        "\n",
        "# Example Rule 6: If you eat healthy, you gain energy.\n",
        "@context(f'{t}')\n",
        "@forall(p)\n",
        "def rule6(p: entity):\n",
        "    if p in Persons and EatHealthy(p):\n",
        "        return Energy(p)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sljtU_f6bx7p",
        "outputId": "ec9137e9-5d37-4336-8299-a00db9977333"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting causal_rules.pyreason\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from numba import jit\n",
        "import time\n",
        "\n",
        "# -------------------------------\n",
        "# Step 1: Simulated LLM Parser\n",
        "# -------------------------------\n",
        "def simulate_llm_parse(user_input: str) -> dict:\n",
        "    \"\"\"\n",
        "    Expanded LLM parser for natural 'what if' and causal queries.\n",
        "    \"\"\"\n",
        "    user_input_lower = user_input.lower()\n",
        "\n",
        "    # Handle \"what if\" queries\n",
        "    if user_input_lower.startswith(\"what if\"):\n",
        "        cause = user_input_lower.replace(\"what if\", \"\").strip(\"?!.\")\n",
        "        return {\n",
        "            \"status\": \"parsed\",\n",
        "            \"query_type\": \"causal_inference\",\n",
        "            \"entities\": [\n",
        "                {\"type\": \"cause\", \"name\": cause},\n",
        "                {\"type\": \"effect\", \"name\": \"outcome\"} # generic effect placeholder\n",
        "            ]\n",
        "        }\n",
        "\n",
        "    # Handle \"causal effect of\" or \"what happens if\"\n",
        "    if \"causal effect of\" in user_input_lower or \"what happens if\" in user_input_lower:\n",
        "        entities = []\n",
        "        if \"on\" in user_input_lower:\n",
        "            parts = user_input_lower.split(\"on\")\n",
        "            if len(parts) == 2:\n",
        "                cause = parts[0].replace(\"causal effect of\", \"\").replace(\"what happens if\", \"\").strip()\n",
        "                effect = parts[1].strip()\n",
        "                if cause:\n",
        "                    entities.append({\"type\": \"cause\", \"name\": cause})\n",
        "                if effect:\n",
        "                    entities.append({\"type\": \"effect\", \"name\": effect})\n",
        "        return {\"status\": \"parsed\", \"query_type\": \"causal_inference\", \"entities\": entities}\n",
        "\n",
        "    # Handle definition queries\n",
        "    if \"define\" in user_input_lower or \"what is\" in user_input_lower:\n",
        "        definition_topic = user_input_lower.replace(\"define\", \"\").replace(\"what is\", \"\").strip()\n",
        "        return {\"status\": \"parsed\", \"query_type\": \"definition\", \"topic\": definition_topic}\n",
        "\n",
        "    # Handle rule listing\n",
        "    if \"list rules\" in user_input_lower:\n",
        "        return {\"status\": \"parsed\", \"query_type\": \"list_rules\"}\n",
        "\n",
        "    return {\"status\": \"unparsable\", \"original_input\": user_input}\n",
        "\n",
        "\n",
        "# -------------------------------\n",
        "# Step 2: Convert Parsed Input\n",
        "# -------------------------------\n",
        "def convert_to_pyreason_input(parsed_input: dict) -> str or None:\n",
        "    \"\"\"\n",
        "    Converts the structured dictionary from the simulated LLM into a format\n",
        "    that PyReason can use.\n",
        "    \"\"\"\n",
        "    if parsed_input.get(\"status\") == \"parsed\":\n",
        "        query_type = parsed_input.get(\"query_type\")\n",
        "\n",
        "        if query_type == \"causal_inference\":\n",
        "            entities = parsed_input.get(\"entities\", [])\n",
        "            cause = next((e[\"name\"] for e in entities if e[\"type\"] == \"cause\"), None)\n",
        "            effect = next((e[\"name\"] for e in entities if e[\"type\"] == \"effect\"), None)\n",
        "            if cause and effect:\n",
        "                return f\"query effect of {cause} on {effect}\"\n",
        "            else:\n",
        "                return None\n",
        "\n",
        "        elif query_type == \"definition\":\n",
        "            topic = parsed_input.get(\"topic\")\n",
        "            if topic:\n",
        "                return f\"define {topic}\"\n",
        "            else:\n",
        "                return None\n",
        "\n",
        "        elif query_type == \"list_rules\":\n",
        "            return \"list rules\"\n",
        "\n",
        "        else:\n",
        "            return None\n",
        "\n",
        "    elif parsed_input.get(\"status\") == \"unparsable\":\n",
        "        return None\n",
        "\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "\n",
        "# -------------------------------\n",
        "# Step 3: Simple Reasoning Engine\n",
        "# -------------------------------\n",
        "def reason_with_rules(pyreason_input: str) -> str:\n",
        "    \"\"\"\n",
        "    Very basic rule matching. In real PyReason, you'd load and evaluate rules.\n",
        "    \"\"\"\n",
        "    rules = {\n",
        "        \"not watering plants\": \"plants may wither\",\n",
        "        \"not doing homework\": \"you might get in trouble\",\n",
        "        \"rain\": \"the ground becomes wet\",\n",
        "        \"ground is wet and sun is shining\": \"it might steam\"\n",
        "    }\n",
        "\n",
        "    for cause, outcome in rules.items():\n",
        "        if cause in pyreason_input:\n",
        "            return f\"If {cause}, then {outcome}.\"\n",
        "    return \"I don't have a rule for that yet.\"\n",
        "\n",
        "\n",
        "# -------------------------------\n",
        "# Step 4: NN + Numba Examples\n",
        "# -------------------------------\n",
        "class SimpleNN(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "        super(SimpleNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.sigmoid(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "def predict_outcome_with_nn(input_data):\n",
        "    input_dim = input_data.shape[1]\n",
        "    hidden_dim = 5\n",
        "    output_dim = 1\n",
        "    model = SimpleNN(input_dim, hidden_dim, output_dim)\n",
        "    input_tensor = torch.tensor(input_data, dtype=torch.float32)\n",
        "    output_probability = model(input_tensor)\n",
        "    return output_probability.detach().numpy()\n",
        "\n",
        "\n",
        "@jit(nopython=True)\n",
        "def fast_array_operation(arr):\n",
        "    result = np.zeros_like(arr)\n",
        "    for i in range(arr.shape[0]):\n",
        "        for j in range(arr.shape[1]):\n",
        "            result[i, j] = arr[i, j] * 2.0 + 1.0\n",
        "    return result\n",
        "\n",
        "\n",
        "# -------------------------------\n",
        "# Step 5: Chatbot Loop\n",
        "# -------------------------------\n",
        "def main_chatbot_loop():\n",
        "    while True:\n",
        "        user_input = input(\"You: \")\n",
        "        if user_input.lower() in [\"quit\", \"exit\"]:\n",
        "            print(\"Chatbot: Goodbye!\")\n",
        "            break\n",
        "\n",
        "        parsed_input = simulate_llm_parse(user_input)\n",
        "        pyreason_input = convert_to_pyreason_input(parsed_input)\n",
        "\n",
        "        if pyreason_input:\n",
        "            response = reason_with_rules(pyreason_input)\n",
        "            print(f\"Chatbot: {response}\")\n",
        "        else:\n",
        "            print(\"Chatbot: I couldn't understand that. Can you rephrase?\")\n",
        "\n",
        "\n",
        "# Example quick tests\n",
        "if __name__ == \"__main__\":\n",
        "    dummy_input = np.array([[0.5, 0.1, 0.9]])\n",
        "    prediction = predict_outcome_with_nn(dummy_input)\n",
        "    print(f\"NN Prediction: {prediction}\")\n",
        "\n",
        "    large_array = np.random.rand(500, 500)\n",
        "    start_time = time.time()\n",
        "    result_numpy = large_array * 2.0 + 1.0\n",
        "    print(f\"NumPy op time: {time.time() - start_time:.6f} sec\")\n",
        "\n",
        "    start_time = time.time()\n",
        "    result_numba = fast_array_operation(large_array)\n",
        "    print(f\"Numba op time: {time.time() - start_time:.6f} sec\")\n",
        "\n",
        "    # Start chatbot\n",
        "    main_chatbot_loop()\n"
      ],
      "metadata": {
        "id": "6BRlTRxhblyn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ea9e65e-a3af-4ebf-bad4-b095094841f5"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NN Prediction: [[0.41763815]]\n",
            "NumPy op time: 0.000827 sec\n",
            "Numba op time: 0.194753 sec\n",
            "You: what if it rains?\n",
            "Chatbot: If rain, then the ground becomes wet.\n",
            "You: what if i don't plants are not watered?\n",
            "Chatbot: I don't have a rule for that yet.\n",
            "You: what if i sleep late?\n",
            "Chatbot: I don't have a rule for that yet.\n",
            "You: what if you sleep late?\n",
            "Chatbot: I don't have a rule for that yet.\n",
            "You: quit\n",
            "Chatbot: Goodbye!\n"
          ]
        }
      ]
    }
  ]
}